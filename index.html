<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Security-Policy" content="default-src 'self' https://agent-gkcp.onrender.com; media-src 'self' blob: mediastream:; script-src 'self' 'unsafe-inline'; connect-src 'self' https://agent-gkcp.onrender.com mediastream:;">
    <title>Assistant Vocal - Production</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .controls {
            margin: 20px 0;
            text-align: center;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            font-size: 16px;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #status {
            margin: 10px 0;
            padding: 15px;
            border-radius: 5px;
            background-color: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            font-size: 16px;
        }
        .error {
            color: red;
            font-weight: bold;
        }
        #timer {
            font-size: 18px;
            font-weight: bold;
            color: #4CAF50;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <h1>Assistant Vocal - Version Production</h1>
    <div class="controls">
        <button id="startRecord">Enregistrer (6 secondes)</button>
        <button id="resetConversation">Réinitialiser la conversation</button>
    </div>
    <div id="timer"></div>
    <div id="status">Prêt à enregistrer...</div>

    <script>
        const API_URL = 'https://agent-gkcp.onrender.com';
        let mediaRecorder;
        let audioChunks = [];
        let recordingTimeout;
        let timerInterval;

        function updateTimer(remainingTime) {
            const timerDiv = document.getElementById('timer');
            if (remainingTime > 0) {
                timerDiv.textContent = `Enregistrement: ${remainingTime} secondes`;
            } else {
                timerDiv.textContent = '';
            }
        }

        async function startRecording() {
            try {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    throw new Error('L\'API MediaDevices n\'est pas supportée sur ce navigateur');
                }

                audioChunks = []; // Réinitialiser les chunks audio
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    }
                });

                mediaRecorder = new MediaRecorder(stream);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    if (audioChunks.length > 0) {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        await processAudio(audioBlob);
                    }
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                document.getElementById('startRecord').disabled = true;
                updateStatus('Enregistrement en cours...');

                // Démarrer le timer
                let timeLeft = 6;
                updateTimer(timeLeft);
                timerInterval = setInterval(() => {
                    timeLeft--;
                    updateTimer(timeLeft);
                    if (timeLeft <= 0) {
                        clearInterval(timerInterval);
                    }
                }, 1000);

                // Arrêter automatiquement après 6 secondes
                recordingTimeout = setTimeout(() => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        clearInterval(timerInterval);
                        document.getElementById('startRecord').disabled = false;
                        updateTimer(0);
                    }
                }, 6000);
                
            } catch (error) {
                console.error('Erreur détaillée:', error);
                let errorMessage = 'Erreur d\'accès au microphone: ';
                
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Permission refusée par l\'utilisateur';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'Aucun microphone détecté';
                } else if (error.name === 'SecurityError') {
                    errorMessage += 'Problème de sécurité - vérifiez que le site est en HTTPS';
                } else {
                    errorMessage += error.message;
                }
                
                updateStatus(errorMessage);
                document.getElementById('status').classList.add('error');
                document.getElementById('startRecord').disabled = false;
                updateTimer(0);
            }
        }

        async function processAudio(audioBlob) {
            try {
                const wavBlob = await convertToWav(audioBlob);
                
                // 1. Transcription
                const formData = new FormData();
                formData.append('file', wavBlob, 'audio.wav');
                
                const transcriptionResponse = await fetch(`${API_URL}/transcribe`, {
                    method: 'POST',
                    body: formData
                });
                const transcriptionData = await transcriptionResponse.json();
                
                if (transcriptionData.error) throw new Error(transcriptionData.error);
                updateStatus('Texte transcrit: ' + transcriptionData.text);

                // 2. Génération de réponse
                const generationResponse = await fetch(`${API_URL}/generate-response`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: transcriptionData.text })
                });
                const generationData = await generationResponse.json();
                
                if (generationData.error) throw new Error(generationData.error);
                updateStatus('Réponse générée: ' + generationData.text);

                // 3. Synthèse vocale
                const ttsResponse = await fetch(`${API_URL}/text-to-speech`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: generationData.text })
                });
                
                if (!ttsResponse.ok) throw new Error('Erreur lors de la synthèse vocale');
                
                const audioBlob = await ttsResponse.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                await audio.play();
                
                updateStatus('Lecture de la réponse terminée');
                document.getElementById('status').classList.remove('error');
                
            } catch (error) {
                console.error('Erreur lors du traitement:', error);
                updateStatus('Erreur: ' + error.message);
                document.getElementById('status').classList.add('error');
            }
        }

        function convertToWav(blob) {
            return new Promise((resolve) => {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const fileReader = new FileReader();
                
                fileReader.onload = async (e) => {
                    const audioBuffer = await audioContext.decodeAudioData(e.target.result);
                    const wavBuffer = audioBufferToWav(audioBuffer);
                    const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                    resolve(wavBlob);
                };
                
                fileReader.readAsArrayBuffer(blob);
            });
        }

        function audioBufferToWav(buffer) {
            const numChannels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            const format = 1;
            const bitDepth = 16;
            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = buffer.length * blockAlign;
            const headerSize = 44;
            const totalSize = headerSize + dataSize;
            const arrayBuffer = new ArrayBuffer(totalSize);
            const view = new DataView(arrayBuffer);

            writeString(view, 0, 'RIFF');
            view.setUint32(4, totalSize - 8, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(view, 36, 'data');
            view.setUint32(40, dataSize, true);

            const channelData = [];
            for (let channel = 0; channel < numChannels; channel++) {
                channelData[channel] = buffer.getChannelData(channel);
            }

            let offset = 44;
            for (let i = 0; i < buffer.length; i++) {
                for (let channel = 0; channel < numChannels; channel++) {
                    const sample = Math.max(-1, Math.min(1, channelData[channel][i]));
                    view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                    offset += bytesPerSample;
                }
            }

            return arrayBuffer;
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        async function resetConversation() {
            try {
                const response = await fetch(`${API_URL}/reset-conversation`, {
                    method: 'DELETE'
                });
                const data = await response.json();
                updateStatus('Conversation réinitialisée');
                document.getElementById('status').classList.remove('error');
            } catch (error) {
                console.error('Erreur lors de la réinitialisation:', error);
                updateStatus('Erreur lors de la réinitialisation de la conversation');
                document.getElementById('status').classList.add('error');
            }
        }

        function updateStatus(message) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
        }

        // Écouteurs d'événements
        document.getElementById('startRecord').addEventListener('click', startRecording);
        document.getElementById('resetConversation').addEventListener('click', resetConversation);
    </script>
</body>
</html>